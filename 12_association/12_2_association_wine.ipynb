{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ItemIDとアイテム名の辞書\n",
    "item_dict = {\n",
    "    'I1': 'フランスワイン',\n",
    "    'I2': 'イタリアワイン',\n",
    "    'I3': 'スペインワイン',\n",
    "    'I4': 'チリワイン',\n",
    "    'I5': '国産ワイン'\n",
    "}\n",
    "\n",
    "# ワインの購買履歴のデータ\n",
    "trans = [\n",
    "    # TID: T1\n",
    "    [1, 'I1'],\n",
    "    [1, 'I2'],\n",
    "    [1, 'I4'],\n",
    "    [1, 'I5'],\n",
    "    # TID: T2\n",
    "    [2, 'I2'],\n",
    "    [2, 'I3'],\n",
    "    [2, 'I5'],\n",
    "    # TID: T3\n",
    "    [3, 'I1'],\n",
    "    [3, 'I2'],\n",
    "    [3, 'I4'],\n",
    "    [3, 'I5'],\n",
    "    # TID: T4\n",
    "    [4, 'I1'],\n",
    "    [4, 'I2'],\n",
    "    [4, 'I3'],\n",
    "    [4, 'I5'],\n",
    "    # TID: T5\n",
    "    [5, 'I1'],\n",
    "    [5, 'I2'],\n",
    "    [5, 'I3'],\n",
    "    [5, 'I4'],\n",
    "    [5, 'I5'],\n",
    "    # TID: T6\n",
    "    [6, 'I2'],\n",
    "    [6, 'I3'],\n",
    "    [6, 'I4']\n",
    "]\n",
    "\n",
    "# pandas DataFrame に変換、確認\n",
    "df = pd.DataFrame(trans, columns=['TID', 'ItemID'])\n",
    "\n",
    "# TIDを重複排除のため集合に変換\n",
    "all_trans = set(df.TID)\n",
    "# |D| : トランザクション数\n",
    "all_trans_len = len(all_trans)\n",
    "\n",
    "# 1つのitemについて、そのitemを含むTIDの集合を辞書で管理\n",
    "count_dict = {}\n",
    "# 全てのitemについて、そのitemを含むTIDの集合をtrans_setに追加\n",
    "for item in df.ItemID.unique():\n",
    "    count_dict[item] = set(df[df['ItemID'] == item].TID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import combinations\n",
    "\n",
    "# サポートカウントの計算\n",
    "def support_count(item_set):\n",
    "    trans_set = []\n",
    "    # item_setの各itemについて、そのitemを含むTIDの集合をtrans_setに追加\n",
    "    for item in item_set:\n",
    "        trans_set.append(count_dict[item])\n",
    "    # trans_set の確認用\n",
    "    # print(trans_set)\n",
    "    # 全itemを含むTIDは、各itemを含むTIDの集合の積集合の要素数\n",
    "    return len(reduce(lambda a, x: a & x, trans_set, all_trans))\n",
    "\n",
    "# サポートの計算\n",
    "def support(itemset):\n",
    "    return support_count(itemset) / all_trans_len\n",
    "\n",
    "# コンフィデンスの計算\n",
    "def confidence(itemset_A, itemset_B):\n",
    "    return support_count(itemset_A | itemset_B) / support_count(itemset_A)\n",
    "\n",
    "# Generate_Candidates(L_{k-1}, k, min_sup_count)\n",
    "def generate_candidates(L, k, min_sup_count):\n",
    "    Ck = []\n",
    "    for l1 in L:\n",
    "        for l2 in L:\n",
    "            # listのインデックスは 0 始まり\n",
    "            if l1[0:k - 2] == l2[0:k - 2] and l1[k - 2] < l2[k - 2]:\n",
    "                c = sorted(list(set(l1) | set(l2)))\n",
    "                # print('k={}: {} | {} = {}'.format(k, l1, l2, c))\n",
    "                for i in combinations(c, k - 1):\n",
    "                    if support_count(i) < min_sup_count:\n",
    "                        break\n",
    "                else:   # 上のbreak文が実行されなかった場合\n",
    "                    Ck.append(c)\n",
    "    return Ck\n",
    "\n",
    "# Apriori アルゴリズムの処理\n",
    "def apriori():\n",
    "    # 全てのアイテム\n",
    "    all_items = sorted(list(set(df.ItemID)))\n",
    "\n",
    "    # 頻出アイテムセットの集合を格納するdict型変数\n",
    "    L = {}\n",
    "\n",
    "    # L1 ← 1つのアイテムからなる頻出アイテムセットの集合\n",
    "    L[1] = [[i] for i in all_items if support_count({i}) >= min_sup_count]\n",
    "    # print('L1 = ', L[1])\n",
    "\n",
    "    # k ← 2\n",
    "    k = 2\n",
    "\n",
    "    while L[k - 1] != []:\n",
    "        Lk = []\n",
    "        Ck = generate_candidates(L[k - 1], k, min_sup_count)\n",
    "        for c in Ck:\n",
    "            # print('{} {}'.format(c, support_count(c)))\n",
    "            if support_count(c) >= min_sup_count:\n",
    "                Lk.append(c)\n",
    "        L[k] = Lk\n",
    "        # print('L{} = {}'.format(k, L[k]))\n",
    "        k = k + 1\n",
    "    \n",
    "    # 和集合\n",
    "    L_union = []\n",
    "    for ln in L.values():\n",
    "        for l in ln:\n",
    "            L_union.append(l)\n",
    "\n",
    "    return L_union\n",
    "\n",
    "# 相関ルールの生成\n",
    "def create_assoc_rules(l, v=0):\n",
    "    # 相関ルールの初期化\n",
    "    assoc_rule = []\n",
    "    # 全ての真部分集合 all_s のリストを初期化\n",
    "    all_s = []\n",
    "    # 全ての真部分集合 all_s の作成\n",
    "    for n in range(1, len(l)):\n",
    "        for i in combinations(l, n):\n",
    "            all_s.append(list(i))\n",
    "    # all_sの確認\n",
    "    #print('all_s = {}'.format(all_s))\n",
    "\n",
    "    # lのサポートカウント\n",
    "    l_support_count = support_count(l)\n",
    "\n",
    "    # 各真部分集合についてコンフィデンスを計算\n",
    "    for s in all_s:\n",
    "        # コンフィデンス(s ⇒ (l-s))\n",
    "        s_support_count = support_count(s)\n",
    "        cnfd = l_support_count / s_support_count\n",
    "        # 確認用\n",
    "        if (v > 0):\n",
    "            print('{} {}/{}={}'.format(s, l_support_count, s_support_count, cnfd))\n",
    "        # 最小コンフィデンス以上のルールを相関ルールに追加\n",
    "        if cnfd >= min_confidence:\n",
    "            # (l-s)\n",
    "            l_s = [i for i in l if i not in s]\n",
    "            sprt = l_support_count / all_trans_len\n",
    "            lift = cnfd / (support_count(l_s) / all_trans_len)\n",
    "            assoc_rule.append([s, l_s, sprt, cnfd, lift])\n",
    "\n",
    "    return assoc_rule\n",
    "\n",
    "# 全ての相関ルールの生成\n",
    "def create_all_assoc_rules():\n",
    "    # 相関ルールの初期化\n",
    "    assoc_rules = []\n",
    "    # Aprioriアルゴリズムで求めた全ての頻出アイテムセットから相関ルールを生成\n",
    "    for l in apriori():\n",
    "        rules = create_assoc_rules(l)\n",
    "        if rules != []:\n",
    "            for r in rules:\n",
    "                assoc_rules.append(r)\n",
    "\n",
    "    return pd.DataFrame(assoc_rules, columns=['L', 'R', 'support', 'confidence', 'lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最小サポート: 0.5\n",
    "min_sup = 0.5\n",
    "# 最小コンフィデンス\n",
    "min_confidence = 0.7\n",
    "# 最小サポートカウント\n",
    "min_sup_count = min_sup * all_trans_len\n",
    "\n",
    "# 相関ルールの確認\n",
    "l = ['I2', 'I3', 'I5']\n",
    "print('相関ルールの生成:', l)\n",
    "create_assoc_rules(l, v=1)\n",
    "#pd.DataFrame(create_assoc_rules(l, v=1), columns=['L', 'R', 'support', 'confidence', 'lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関ルールの生成\n",
    "print('全ての相関ルールの生成:')\n",
    "df_rules = create_all_assoc_rules()\n",
    "# 確認\n",
    "df_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- support: 最小サポートが足切り規準となり、一定以上の重要性を持つルールだけが残されている\n",
    "- confidence: 確信度が高いと、事象は一緒に起きやすい（商品は一緒に買われやすい）\n",
    "- lift: 相関関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lift値が1以上のルールについて、confidenceで降順にソートし、上位20を表示\n",
    "df_rules.query('lift>=1').sort_values('confidence', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lift値が1以上, confidenceが1のルールについて、liftで降順にソートして表示\n",
    "df_rules.query('lift>=1 and confidence==1').sort_values('lift', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
